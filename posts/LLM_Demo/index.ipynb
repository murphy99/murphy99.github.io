{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbe92e6",
   "metadata": {},
   "source": [
    "---\n",
    "title: Easily Build Customized LLMs\n",
    "date: \"2025-07-15\"\n",
    "image: llm_photo.png\n",
    "categories: [Python, OPENAI, LLMs, Jupyter, OBBBA]\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "One of the use cases for localized LLMs is to help digest new bills, policies, and/or court decisions in an efficient and expedient manner. Journalists frequently encounter brand new material before it becomes public and cannot store the document on any server.\n",
    "\n",
    "In this model, you need to add a complex, detailed, and involved document, in this case it’s the summary of the “One Big Beautiful Bill Act” or some might call the “One Big Bad Bill Act.” Whatever you call it, we’ll refer to it as the OBBBA. It does a pretty good job and you can see how you structure your query makes a difference on the response. Some prompts will be better than others.\n",
    "\n",
    "For best results, I have found that adding other analysis improves the responses and contexts, but here we are just going to have the OBBA summary and text from the government website as a demonstration on how this can be used and test it to see if it would be comprehensive enough for journalists to use.\n",
    "\n",
    "This model uses minimally trained model from OPENAI, and fairly inexpensive of all the models to do the query. Since the subject matter is so narrow - we do not need a big model - just big enough to be fairly responsive to our queries.\n",
    "\n",
    "Adding more PDFs will get a richer and more comprehensive output. Working on your queries or prompts will also improve the results.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f036d",
   "metadata": {},
   "source": [
    "### Python Packages Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f802c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install in packages (pip) in terminal - if missing\n",
    "#!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "#pip install duckdb\n",
    "import duckdb\n",
    "#pip install llama_index_core\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "import os #built in package\n",
    "#pip install openai\n",
    "import openai\n",
    "#pip install textwrap\n",
    "import textwrap \n",
    "#pip install llama_index.vector_stores.duckdb\n",
    "import llama_index.vector_stores.duckdb\n",
    "#pip install llama-index-embeddings-openai\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "#pip install llama-index-llms-openai\n",
    "from llama_index.llms.openai import OpenAI\n",
    "#pip install gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf14a0a",
   "metadata": {},
   "source": [
    "### The LLM creates a vector store everytime it runs. So we delete it before storing the new vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3698a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File deleted successfully\n"
     ]
    }
   ],
   "source": [
    "file_path = 'persist/my_vector_store.duckdb'\n",
    "\n",
    "# Check if file exists\n",
    "if os.path.exists(file_path):\n",
    "  #Delete the file\n",
    "  os.remove(file_path)\n",
    "  print(\"File deleted successfully\")\n",
    "else:\n",
    "  print(\"File doesn't exist - first run - it's all good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae6bc5",
   "metadata": {},
   "source": [
    "### Load OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63a6ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "#load_dotenv()\n",
    "\n",
    "load_dotenv(dotenv_path=\"secrets/.env\")\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cab274b",
   "metadata": {},
   "source": [
    "### Import the indexing packages to store the indexing in DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed50eaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.duckdb import DuckDBVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "vector_store = DuckDBVectorStore(\"my_vector_store.duckdb\", persist_dir=\"persist/\")\n",
    "documents = SimpleDirectoryReader(\"/Users/Eileen/Desktop/GoData/Blog/posts/LLM_Demo/OBBBA/\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed887062",
   "metadata": {},
   "source": [
    "### Index being created on PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d50ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58abdc66",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2180de",
   "metadata": {},
   "source": [
    "LLM_Demo is deployed here: [](https://huggingface.co/spaces/GoData/LLM_Demo)\n",
    "\n",
    "Or scroll below and try it out! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e3c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://godata-llm-demo.hf.space\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x121cb97f0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Create an IFrame object\n",
    "# Parameters: url, width, height\n",
    "iframe = IFrame(src=\"https://godata-llm-demo.hf.space\", width=1000, height=5000)\n",
    "# Display the iframe\n",
    "iframe"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
