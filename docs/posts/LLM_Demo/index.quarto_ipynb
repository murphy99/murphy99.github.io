{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "jupyter: python3\n",
        "---"
      ],
      "id": "751cfa80"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install core components\n",
        "#pip3 install llama-index-core \n",
        "#pip3 install python-dotenv \n",
        "#pip3 install duckdb \n",
        "#pip3 install gradio\n",
        "#pip install pyyaml\n",
        "\n",
        "# Install integrations\n",
        "#pip3 install llama-index-llms-openai\n",
        "#pip3 install llama-index-embeddings-openai\n",
        "#pip3 install llama_index.vector_stores.duckdb\n",
        "\n",
        "# Install integrations\n",
        "#pip install llama-index-llms-openai\n",
        "#pip install llama-index-embeddings-openai\n",
        "#pip install dotenv"
      ],
      "id": "90932a1f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Install in packages (pip) in terminal - if missing\n",
        "import yaml\n",
        "#!pip install python-dotenv\n",
        "from dotenv import load_dotenv\n",
        "#pip install duckdb\n",
        "import duckdb\n",
        "#pip install llama_index_core\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "import os #built in package\n",
        "#pip install openai\n",
        "import openai\n",
        "#pip install textwrap\n",
        "import textwrap \n",
        "#pip install llama_index.vector_stores.duckdb\n",
        "import llama_index.vector_stores.duckdb\n",
        "#pip install llama-index-embeddings-openai\n",
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "#pip install llama-index-embeddings-openai\n",
        "#import llama-index-embeddings-openai\n",
        "#pip install gradio\n",
        "import gradio as gr"
      ],
      "id": "b8bb03ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from llama_index.llms.openai import OpenAI\n"
      ],
      "id": "24b72f1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "file_path = 'persist/my_vector_store.duckdb'\n",
        "\n",
        "# Check if file exists\n",
        "if os.path.exists(file_path):\n",
        "  #Delete the file\n",
        "  os.remove(file_path)\n",
        "  print(\"File deleted successfully\")\n",
        "else:\n",
        "  print(\"File doesn't exist - first run - it's all good\")"
      ],
      "id": "e1bdea09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from dotenv import load_dotenv\n",
        "#load_dotenv()\n",
        "# Point to the secrets/.env file\n",
        "load_dotenv(dotenv_path=\"secrets/.env\")\n",
        "\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "id": "6b9dfac5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.vector_stores.duckdb import DuckDBVectorStore\n",
        "from llama_index.core import StorageContext\n",
        "\n",
        "vector_store = DuckDBVectorStore(\"my_vector_store.duckdb\", persist_dir=\"persist/\")\n",
        "documents = SimpleDirectoryReader(\"/Users/Eileen/Desktop/GoData/Blog/posts/LLM_Demo/PDFs/\").load_data()"
      ],
      "id": "8ed3e91f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)"
      ],
      "id": "1171ecb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Create a custom theme with blue as the primary color\n",
        "#theme = gr.themes.Default()  \n",
        "#theme = gr.themes.Default(primary_hue=\"blue\", font=[\"Helvetica\", \"sans-serif\"])\n",
        "\n",
        "def greet(query):\n",
        "    #print(\"Before query\")  # Debugging\n",
        "    query_engine = index.as_query_engine()\n",
        "    response = query_engine.query(query)\n",
        "    #print(\"After query\")   # Debugging\n",
        "    return str(response)\n",
        "\n",
        "gr.Interface(\n",
        "  fn=greet,\n",
        "  inputs=gr.Textbox(lines=1, placeholder=\"Enter your query here...\",\n",
        "  label=\"Your Query\"),\n",
        "  outputs=gr.Textbox(label=\"Response\")\n",
        "  )\n",
        "  #.launch(share=False)"
      ],
      "id": "4bea66af",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/Eileen/.virtualenvs/godata/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}